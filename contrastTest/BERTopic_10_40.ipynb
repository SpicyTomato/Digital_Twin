{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd75dbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model not found, training model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8346816c96bc4a9babf53bf3265f0405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-12 14:09:32,861 - BERTopic - Reduced dimensionality\n",
      "2023-05-12 14:09:32,907 - BERTopic - Clustered reduced embeddings\n",
      "2023-05-12 14:09:33,628 - BERTopic - Reduced number of topics from 42 to 10\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bertopic import BERTopic\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from bertopic.representation import KeyBERTInspired, OpenAI\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from typing import List, Union\n",
    "\n",
    "# 读取文件\n",
    "df = pd.read_excel('../file.xlsx', header=None, names=['Abstract', 'Date'], skiprows=[0])\n",
    "\n",
    "\n",
    "# 删除空值\n",
    "df = df.dropna()\n",
    "\n",
    "# 将Abstract列的内容保存至docs变量中\n",
    "docs = df['Abstract'].tolist()\n",
    "timestamp = df['Date'].tolist()\n",
    "\n",
    "\n",
    "for number_of_topics in range(10,50,10):\n",
    "    # 停用词\n",
    "    vectorizer_model = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "    # 常用词\n",
    "    ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)\n",
    "\n",
    "    sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "    embeddings = sentence_model.encode(docs, show_progress_bar=True)\n",
    "\n",
    "    topic_model = BERTopic(verbose=True, nr_topics=10, vectorizer_model=vectorizer_model, ctfidf_model=ctfidf_model)\n",
    "\n",
    "    topic_model.fit_transform(docs, embeddings)\n",
    "\n",
    "    topics_id  = topic_model.get_document_info(docs)\n",
    "\n",
    "    topic_keywords = topic_model.get_topics()\n",
    "\n",
    "    number_of_topics = 10\n",
    "    topics = []\n",
    "    # print(topics)\n",
    "    for i in topic_keywords:\n",
    "        if i != -1:\n",
    "    #         print(i)\n",
    "            temp = []\n",
    "            for item in topic_keywords[i]:\n",
    "                temp.append(item[0])\n",
    "            topics.append(temp)\n",
    "        else:\n",
    "            continue\n",
    "    print(topics_id[topics_id['Topic'] != -1])\n",
    "\n",
    "    # 使用筛选条件创建一个新的DataFrame\n",
    "    filtered_topics_id = topics_id[topics_id['Topic'] != -1]\n",
    "\n",
    "    # 使用lambda函数将文本拆分为小写单词列表\n",
    "    tokenized_texts = filtered_topics_id['Document'].apply(lambda x: x.lower().split()).tolist()\n",
    "\n",
    "\n",
    "    dictionary = Dictionary(tokenized_texts)\n",
    "\n",
    "    missing_keywords = set()\n",
    "    for topic in topics:\n",
    "        for keyword in topic:\n",
    "            if keyword not in dictionary.token2id:\n",
    "                missing_keywords.add(keyword)\n",
    "\n",
    "    print(\"Missing keywords:\", missing_keywords)\n",
    "    filtered_topics = [[keyword for keyword in topic if keyword not in missing_keywords] for topic in topics]\n",
    "\n",
    "    coherence_model = CoherenceModel(topics=filtered_topics,\n",
    "                                           texts=tokenized_texts,\n",
    "                                           dictionary=dictionary,\n",
    "                                           coherence='c_v')\n",
    "    coherence = coherence_model.get_coherence()\n",
    "    print(\"Topic Coherence:\", coherence)\n",
    "\n",
    "    def jaccard_similarity(topic1, topic2):\n",
    "        topic1_set = set(topic1)\n",
    "        topic2_set = set(topic2)\n",
    "        intersection = len(topic1_set.intersection(topic2_set))\n",
    "        union = len(topic1_set.union(topic2_set))\n",
    "        return intersection / union\n",
    "\n",
    "    def topic_diversity(topics):\n",
    "        similarity_sum = 0\n",
    "        num_topic_pairs = 0\n",
    "        for i in range(len(topics)):\n",
    "            for j in range(i + 1, len(topics)):\n",
    "                similarity_sum += jaccard_similarity(topics[i], topics[j])\n",
    "                num_topic_pairs += 1\n",
    "        average_similarity = similarity_sum / num_topic_pairs\n",
    "        diversity = 1 - average_similarity\n",
    "        return diversity\n",
    "\n",
    "    diversity = topic_diversity(filtered_topics)\n",
    "    print(\"Topic Diversity:\", diversity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e88dde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Document  Topic   \n",
      "1     Over the last few decades, our digitally expan...      0  \\\n",
      "2     The increasing digitization of the economy mea...      0   \n",
      "4     The manufacturing sector is one of the areas w...      0   \n",
      "6     A Digital Twin is an auspicious cross-industry...      0   \n",
      "7     Digital twin has the potential to be an import...      0   \n",
      "...                                                 ...    ...   \n",
      "2602  Cyber-physical systems revolve around context ...      0   \n",
      "2603  Modelling the fast dynamics of power converter...      0   \n",
      "2604  With continued global market growth and an inc...      0   \n",
      "2605  This chapter gives an industry perspective of ...      0   \n",
      "2606  The evolution of the Internet of Things and di...      0   \n",
      "\n",
      "                           Name   \n",
      "1     0_digital_twin_data_model  \\\n",
      "2     0_digital_twin_data_model   \n",
      "4     0_digital_twin_data_model   \n",
      "6     0_digital_twin_data_model   \n",
      "7     0_digital_twin_data_model   \n",
      "...                         ...   \n",
      "2602  0_digital_twin_data_model   \n",
      "2603  0_digital_twin_data_model   \n",
      "2604  0_digital_twin_data_model   \n",
      "2605  0_digital_twin_data_model   \n",
      "2606  0_digital_twin_data_model   \n",
      "\n",
      "                                            Top_n_words  Probability   \n",
      "1     digital - twin - data - model - process - prop...     0.858885  \\\n",
      "2     digital - twin - data - model - process - prop...     0.979553   \n",
      "4     digital - twin - data - model - process - prop...     0.955853   \n",
      "6     digital - twin - data - model - process - prop...     1.000000   \n",
      "7     digital - twin - data - model - process - prop...     1.000000   \n",
      "...                                                 ...          ...   \n",
      "2602  digital - twin - data - model - process - prop...     0.819620   \n",
      "2603  digital - twin - data - model - process - prop...     1.000000   \n",
      "2604  digital - twin - data - model - process - prop...     1.000000   \n",
      "2605  digital - twin - data - model - process - prop...     0.421983   \n",
      "2606  digital - twin - data - model - process - prop...     0.818310   \n",
      "\n",
      "      Representative_document  \n",
      "1                       False  \n",
      "2                       False  \n",
      "4                       False  \n",
      "6                       False  \n",
      "7                       False  \n",
      "...                       ...  \n",
      "2602                    False  \n",
      "2603                    False  \n",
      "2604                    False  \n",
      "2605                    False  \n",
      "2606                    False  \n",
      "\n",
      "[1538 rows x 6 columns]\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
